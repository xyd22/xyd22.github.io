---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. Suspendisse condimentum, libero vel tempus mattis, risus risus vulputate libero, elementum fermentum mi neque vel nisl. Maecenas facilisis maximus dignissim. Curabitur mattis vulputate dui, tincidunt varius libero luctus eu. Mauris mauris nulla, scelerisque eget massa id, tincidunt congue felis. Sed convallis tempor ipsum rhoncus viverra. Pellentesque nulla orci, accumsan volutpat fringilla vitae, maximus sit amet tortor. Aliquam ultricies odio ut volutpat scelerisque. Donec nisl nisl, porttitor vitae pharetra quis, fringilla sed mi. Fusce pretium dolor ut aliquam consequat. Cras volutpat, tellus accumsan mattis molestie, nisl lacus tempus massa, nec malesuada tortor leo vel quam. Aliquam vel ex consectetur, vehicula leo nec, efficitur eros. Donec convallis non urna quis feugiat.

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üìñ Educations
<div class="education-box"> 
<div class="education-box-image">
<img src="images/logo/Tsinghua_logo.png" alt="sym" width="100%">
</div>
<div class="education-box-text" markdown="1">
<a href="https://www.tsinghua.edu.cn/en/" style="text-decoration: none;"><strong>Tsinghua University</strong></a>
<p> <strong>B.E. in Electronic Engineering</strong> </p>
<p> GPA: 3.92/4.00 </p>
<p> <i>2022.09 - 2026.06</i> (Expected) </p>
<p> <i>Beijing, China</i> </p>
</div>
</div>

<div class="education-box"> 
<div class="education-box-image">
<img src="images/logo/Cornell_logo.png" alt="sym" width="100%">
</div>
<div class="education-box-text" markdown="1">
<a href="https://www.cornell.edu/" style="text-decoration: none;"><strong>Cornell University</strong></a>
<p> <strong>Exchange Student</strong> </p>
<p> GPA: 4.30/4.30 </p>
<p> <i>2025.01 - 2025.05</i></p>
<p> <i>Ithaca, New York, United States</i> </p>
</div>
</div>


# üíª Research Experiences

<div class="education-box"> 
<div class="education-box-image">
<img src="images/logo/Berkeley_logo.png" alt="sym" width="100%">
</div>
<div class="education-box-text" markdown="1">
<a href="https://me.berkeley.edu/laboratories/lin-lab/" style="text-decoration: none;"><strong>Lin Lab</strong></a>, 
<a href="https://www.berkeley.edu/" style="text-decoration: none;"><strong>University of California, Berkeley</strong></a>
<p> Supervisor: <a href="https://lwlin.me.berkeley.edu/" style="text-decoration: none;"><strong>Prof. Liwei Lin</strong></a> </p>
<p> Research Topic: Piezoelectric Micromachined Ultrasonic Transducers (PMUTs) </p>
<p> <i>2025.05 - 2025.09</i> </p>
</div>
</div>

<div class="education-box"> 
<div class="education-box-image">
<img src="images/logo/Cornell_logo.png" alt="sym" width="100%">
</div>
<div class="education-box-text" markdown="1">
<a href="https://www.scifilab.org/" style="text-decoration: none;"><strong>SciFi Lab</strong></a>, 
<a href="https://www.cornell.edu/" style="text-decoration: none;"><strong>Cornell University</strong></a>
<p> Supervisor: <a href="https://czhang.org/" style="text-decoration: none;"><strong>Prof. Cheng Zhang</strong></a> </p>
<p> Research Topic: Ultrasonic Sensing, Active Acoustic Sensing </p>
<p> <i>2025.01 - 2025.06</i> </p>
</div>
</div>

<div class="education-box"> 
<div class="education-box-image">
<img src="images/logo/Tsinghua_logo.png" alt="sym" width="100%">
</div>
<div class="education-box-text" markdown="1">
<a href="https://www.sic.tsinghua.edu.cn/en/" style="text-decoration: none;"><strong>School of Integrated Circuit</strong></a>, 
<a href="https://www.tsinghua.edu.cn/en/" style="text-decoration: none;"><strong>Tsinghua University</strong></a>
<p> Supervisor: <a href="https://www.sic.tsinghua.edu.cn/en/info/1078/1373.htm" style="text-decoration: none;"><strong>Prof. Tianling Ren</strong></a> </p>
<p> Research Topic: Silent Speech Interfaces, Haptics </p>
<p> <i>2024.01 - 2024.11</i> </p>
</div>
</div>

<br>
<br>

<!-- # üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìù Publications 
<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">IEEE MEMS 2026</div>
      <img src='images/publications/PMUTButton_MEMS_20251020.png' alt="sym" width="100%">
      <!-- <video src="images/publications/objnerf2.mp4" width="100%" autoplay muted loop></video> -->
    </div>
  </div>

  <div class='paper-box-text' markdown="1">

  <!-- <a href="https://objnerf.github.io" style="text-decoration: none;"><strong>Obj-NeRF: Extracting Object NeRFs from Multi-view Images</strong></a> -->
  <p> <strong>AN ACOUSTIC TOUCH-MOTION BUTTON WITH HAPTIC FUNCTION VIA AN IN-SITU FABRICATED ELASTOMERIC LENS ATOP PMUTS</strong></p>

  <p> Declan Fitzgerald*, <strong>Yudong Xie*</strong>, Sean Isomatsu, Nikita Lukhanin, Zihan Wang, Liwei Lin </p>
  <!-- <p> <i> arXiv </i> </p> -->

  <p><i>The 39th International Conference on Micro Electro Mechanical Systems (IEEE MEMS 2026)</i></p>

  <a href="docs/PMUTButton_MEMS_20251020.pdf"> <strong>Abstract</strong> </a>
  <!-- <a href="https://objnerf.github.io" ><strong>Project</strong></a>,  -->
  <!-- <a href="https://arxiv.org/abs/2311.15291" ><strong>Paper</strong></a>,  -->
  <!-- <a href=""><strong>Code</strong></a>,  -->
  <!-- <a href="https://www.youtube.com/watch?v=VEwYrSPFatg"><strong>Video</strong></a>, 
  <a href="sources/paper_objnerf/paper.pdf"><strong>PDF</strong></a> -->
  <!-- <a href=""><strong>BibTex</strong></a>  -->
  <!-- <a href=""><strong>Supp</strong></a>,  -->
  <!-- <a href=""><strong>Poster</strong></a>,  -->
  <!-- <a href=""><strong>Slides</strong></a> -->
  <!-- <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->

  <!-- - Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

  </div>
</div>

<div class='paper-box'> 

  <div class='paper-box-image'>
    <div>
      <div class="badge">ISWC '25</div>
      <img src='images/publications/Echoforce_ISWC_20250717.png' alt="sym" width="100%">
    </div>
  </div>

  <div class='paper-box-text' markdown="1">
  <a href="https://dl.acm.org/doi/10.1145/3715071.3750405"  style="text-decoration: none;"><strong>EchoForce: Continuous Grip Force Estimation from Skin Deformation Using Active Acoustic Sensing on a Wristband</strong></a>

  <p>Kian Mahmoodi*, <strong>Yudong Xie*</strong>, Tan Gemicioglu*, Chi-Jung Lee, Jiwan Kim, Cheng Zhang</p>
  <p><i>In Proceedings of the 2025 ACM International Symposium on Wearable Computers (ISWC ‚Äô25)</i></p>

  <a href="https://dl.acm.org/doi/10.1145/3715071.3750405"><strong>Paper</strong></a>
  <!-- <a href="../sources/paper_iwcmc/codes.zip" download><strong>Code</strong></a>,  -->
  <!-- <a href="../sources/paper_iwcmc/slides.pdf" download><strong>Slides</strong></a>,  -->
  <!-- <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:4uNrrGSRwJgJ:scholar.google.com/&output=citation&scisdr=ClFyCqlnEM2dlci8V2k:AFWwaeYAAAAAZWK6T2nnKfpSbHf8SzuCl9ZIghU&scisig=AFWwaeYAAAAAZWK6T12eM1unCqehCl_RtPFF6Qc&scisf=4&ct=citation&cd=-1&hl=en"><strong>BibTex</strong></a>  -->

  </div>
</div>

<div class='paper-box'> 

  <div class='paper-box-image'>
    <div>
      <div class="badge">In submission</div>
      <img src='images/publications/SilentSpeech_Arxiv_20250920.png' alt="sym" width="100%">
    </div>
  </div>

  <div class='paper-box-text' markdown="1">
  <a href="https://dl.acm.org/doi/10.1145/3715071.3750405"  style="text-decoration: none;"><strong>Silent Speech Sentence Recognition with Six-Axis Accelerometers using Conformer and CTC Algorithm</strong></a>

  <p><strong>Yudong Xie</strong>, Zhifeng Han, Qinfan Xiao, Liwei Liang, Luqi Tao, Tianling Ren</p>
  <!-- <p><i>In Proceedings of the 2025 ACM International Symposium on Wearable Computers (ISWC ‚Äô25)</i></p> -->

  <a href="https://doi.org/10.48550/arXiv.2502.17829"><strong>Preprint</strong></a>

  </div>
</div>

<!-- - Jida Zhang, <strong>Zhiyi Li</strong>, Zijian Zhang, <a href="https://ieeexplore.ieee.org/abstract/document/10122216/" style="text-decoration: none;">Wideband Active RISs: Architecture, Modeling, and Beamforming Design</a>, <i>IEEE Communications Letters</i>, vol. 27, pp. 1899-1903, Sep. 2023. 

---

- <strong>Zhiyi Li</strong>, Jida Zhang, Jieao Zhu, Linglong Dai, <a href="https://arxiv.org/abs/2310.15901" style="text-decoration: none;">Enhancing Energy Efficiency for Reconfigurable Intelligent Surfaces with Practical Power Models</a>, <i>arXiv preprint arXiv:2310.15901</i> (2023).  -->

<br>

# üéñ Honors and Awards
- *2025.10* &nbsp; "December 9th" Scholarship (~$2800)
- *2024.10* &nbsp; National Scholarship (~$1400)
- *2024.10* &nbsp; Tsinghua Alumni Zhihua Integrated Circuit Scholarship (~$1400)
- *2023.10* &nbsp; National Scholarship (~$1400)


<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

<!-- # üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->